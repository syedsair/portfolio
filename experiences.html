<!DOCTYPE HTML>
<html>
	<head>
		<title>Syed Sair Ali - Full Stack AI Engineer</title>
		<link rel="icon" type="image/x-icon" href="images/logo.svg">
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header" class="alt">
						<a href="index.html"><span class="logo"><img src="images/logo.svg" alt="" /></span></a>
						<a href="index.html"><h1>Syed Sair Ali</h1></a>
						<p>
							<b>AI Architect</b> | <b>Data Engineer</b> | <b>Cloud Enthusiast</b> | <b>Data Analyst</b>
							<br>
							Building <b>AI</b> Agents That Drive <b>Smarter</b>, <b>Faster</b> Business Decisions
						</p>
					</header>

				<!-- Nav -->
					<nav id="nav">
						<ul>
							<li><a href="#experience">Experiences</a></li>
						</ul>
					</nav>

				<!-- Main -->
					<div id="main">
							<!-- Experience -->
							<section id="experience" class="main">
								<div class="spotlight">
									<div class="content">
										<header class="major">
											<h2><b>Full Stack AI</b> Engineer at <b>BitFicial</b> <br></h2>
										</header>
										<p>
											<ul>
												<li>
													Built a <b>Voice AI</b> agent using <b>VAPI</b>, <b>Make.com</b>, and <b>Zapier</b>, capable of leveraging multiple agent tools to 
													perform a wide range of tasks â€” including sending <b>SMS</b> updates, <b>booking appointments</b>, processing 
													<b>user inputs</b>, <b>retrieving data</b> based on queries, and responding with <b>actionable insights</b>, 
													among other capabilities.
												</li>
												<li>
													Engineered a <b>user-specific</b> AI assistant using <b>OpenAI (GPT-4)</b>, <b>LangChain</b>, and a suite of Python data processing libraries <b>(pandas, NumPy, scikit-learn)</b> within a <b>Django</b> backend.
													Integrated with <b>Apple Health</b> data pipelines to ingest, normalize, and analyze <b>multi-dimensional</b> health metrics <b>(sleep, heart rate, HRV, steps, etc.)</b> in real time.
													Designed and implemented a <b>LangChain-powered</b> agent architecture with <b>dynamic tool-calling</b> capabilities using 
													<b>custom tools</b> and <b>toolkits</b>. Built <b>contextual memory</b> modules and <b>vector-based retrieval</b> systems for user-specific 
													data embeddings (via <b>Pinecone</b>), enabling natural language query resolution on <b>personal health insights</b>.
												</li>
												<li>
													Implemented robust backend infrastructure for:
													<ul>
														<li>
															<b>Stateful</b> chat and session <b>context management</b>
														</li>
														<li>
															<b>Token optimization</b> strategies to stay within LLM context window limits
														</li>
														<li>
															<b>Access control</b> layers ensuring strict user-level data isolation
														</li>
														<li>
															<b>Tool routing</b> logic to invoke the appropriate function/tool based on <b>user intent</b>
														</li>
													</ul>
												</li>
												<li>
													This solution enabled true <b>chat-with-your-own-data</b> capabilities: the LLM agent could only 
													access and reason over data tied to the <b>authenticated</b> user (metrics, historical chats, 
													preferences, and behavioral patterns), resulting in a <b>hyper-personalized virtual health 
													assistant</b> experience.
												</li>
												<li>
													Developed an all-in-one, tool-calling agent using <b>Python</b> and <b>LangChain</b>, designed to orchestrate multiple tools and workflows within a unified agent architecture. 
													Key capabilities included:
													<ul>
														<li>
															<b>User-specific query resolution</b>: Dynamically queried relational databases to retrieve and respond with user-specific data across multiple tables and schemas.
														</li>
														<li>
															<b>Transactional data lookup</b>: Implemented structured retrieval mechanisms to fetch matching records from high-volume transactional databases using optimized SQL queries.
														</li>
														<li>
															<b>Modular API integration</b>: Integrated multiple third-party and internal replier APIs, with tool-based routing logic to handle diverse use cases (each use case mapped to a distinct tool).
														</li>
														<li>
															<b>Research & analysis pipeline</b>: Built tools for contextual topic research, aggregating data from APIs, knowledge bases, and LLMs to generate comprehensive insights or feed downstream processes.
														</li>
														<li>
															<b>Automated reporting engine</b>: Designed and implemented a reporting toolchain where metadata for various reports is generated via LangChain tools and transmitted to an endpoint for PDF generation using WeasyPrint (HTML to PDF conversion).
														</li>
													</ul>
												</li>
												<li>
													This agent served as a <b>scalable</b> and <b>extensible</b> backbone for automated <b>data-driven</b> workflows, <b>API orchestration</b>, and <b>personalized</b> user interactions.
												</li>
											</ul>
										</p>
									</div>
									<span class="image"><img src="images/bitficial.jpg" alt="" /></span>
								</div>
								<hr>
								<div class="spotlight">
									<div class="content">
										<header class="major">
											<h2>Senior <b>Data Engineer</b> at <b>BitFicial</b> <br></h2>
										</header>
										<p>
											<ul>
												<li>
													Built a sophisticated <b>royalty dashboard</b> application from scratch. 
													Leveraging <b>Django</b> as the backend framework and Django's templates for the frontend, 
													I seamlessly integrated various components to create a seamless user experience. 
													The project required handling <b>large volumes of data</b>, necessitating efficient data management techniques. 
													To automate recurring tasks, I implemented <b>cron jobs</b>, ensuring timely updates and data <b>synchronization</b>. 
													Additionally, I utilized <b>JavaScript</b> and <b>Python</b> to enhance the application's functionality and interactivity. 
													Deploying the application on <b>AWS</b> further demonstrated my proficiency in <b>cloud computing</b> and scalability. 
													This project not only challenged me to think critically and creatively, 
													but it also fortified my skills in full-stack development and data handling.
												</li>
												<li>
													Managed data team on a groundbreaking project that entailed the deployment of a <b>machine learning</b> model 
													API and a robust backend. <b>Python</b> served as the primary language for developing the machine learning model 
													API, which was meticulously crafted to deliver accurate predictions and insights. 
													Leveraging my expertise in <b>cloud computing</b>, I successfully deployed both the model API and 
													the backend on the <b>Google Cloud Platform (GCP)</b>, ensuring scalability and high availability. 
													To streamline the data flow and processing, I implemented efficient <b>data pipelines</b> on GCP, 
													facilitating seamless integration between the model API and the backend. 
													This project challenged me to apply my skills in <b>Python</b> programming, <b>ML</b>, 
													and <b>cloud deployments</b>.
												</li>
												<li>
													Worked on an impactful project that involved <b>data synchronization</b> from various sources using <b>SyncHub</b>. 
													I effectively integrated data from platforms such as <b>Xero</b> and <b>Unleashed</b>, ensuring accurate 
													and <b>up-to-date</b> information for analysis. Leveraging my expertise in data manipulation and analysis, 
													I generated valuable <b>insights</b> from the integrated data sets. To effectively communicate these 
													insights to clients, I leveraged <b>Power BI</b> to create visually appealing and informative <b>dashboards</b>. 
													These dashboards provided clients with a comprehensive view of their business performance and key 
													metrics, empowering them to make <b>data-driven decisions</b>. This project allowed me to demonstrate 
													my proficiency in <b>data analysis</b>, <b>data integration</b>, and <b>visualization</b>, showcasing my ability to 
													deliver <b>actionable insights</b> to clients.
												</li>
											</ul>
										</p>
									</div>
									<span class="image"><img src="images/bitficial.jpg" alt="" /></span>
								</div>
								<hr>
								<div class="spotlight">
									<div class="content">
										<header class="major">
											<h2><b>Python/Data</b> Engineer at <b>Developers Studio</b> <br></h2>
										</header>
										<p>
											<ul>
												<li>
													<b>Leading data engineering team</b>, I oversaw the collection of diverse data types from multiple sources and unified
													them into a single database. We utilized <b>advanced data integration</b> techniques, including <b>ML</b>
													algorithms, to merge, cleanse, and standardize the data. Our efforts resulted in a user-friendly <b>search engine</b>
													that met our specific requirements and provided reliable and accurate information.
												</li>
												<li>
													Optimized the <b>cron jobs</b> and reduced execution times by <b>30%</b>, enabling the data team to run the jobs every hour
													instead of once a day. This improved data freshness and availability. I analyzed the existing jobs, streamlined the
													process, and eliminated unnecessary steps to create a more efficient workflow.
												</li>
											</ul>
										</p>
									</div>
									<span class="image"><img src="images/ds.png" alt="" /></span>
								</div>
								<hr>
								<div class="spotlight">
									<div class="content">
										<header class="major">
											<h2><b>Data</b> Engineer at <b>ML Sense</b> <br></h2>
										</header>
										<p>
											<ul>
												<li>
													Worked with the data science team, and wrote multiple <b>Python/PySpark</b> scripts, to fetch data from different apis, and
												<b>scheduled</b> them to run daily and append the data into <b>Azure Databricks Spark tables</b>.
												</li>
												<li>
													Converted <b>raw JSON data streams</b>, coming into the <b>data lake</b>, into <b>analyzed dashboard</b> in Azure <b>Databricks</b>. Cleaning was
											done by scheduled <b>Python scripts</b> and <b>SQL queries</b>.
												</li>
												<li>
													Created <b>GCP Cloud Audit tool</b> with the help of Cloud <b>Audit logs</b>, <b>BigQuery</b> and <b>Cloud Functions</b>. The tool provides complete
											and precise information about <b>each resource</b>, created in a project. The information contained <b>Resource Name</b>, <b>Creation
											Time</b>, <b>Update Time</b>, <b>Creator (Service Account/User)</b>, <b>Project</b>, <b>Cost</b>, <b>Data Processed</b> etc.
												</li>
												<li>
													Created an <b>ETL</b> pipeline using <b>Cloud Functions</b>, <b>Scheduler</b> and <b>Bigquery</b>. This procedure gradually scraped almost <b>27 million</b>
											records from the source, <b>cleaned</b> incoming data, and then stored it in <b>Cloud SQL</b> on daily basis. This data was then used for
											a <b>dashboard</b> for a client.
												</li>
												<li>
													After in-depth data analysis, designed and created <b>interactive dashboards</b> for multiple clients in <b>Tableau</b>.
												</li>
												<li>
													Used <b>Django and React</b> to create a web application, <b>deployed to GCP</b>. Scheduled data fetch from <b>Facebook API</b>, <b>Trueclicks</b>
											and <b>Google Display and Video (DV 360)</b> and wrote python scripts in <b>Django backend</b> and <b>Cloud Functions</b> to analyze the
											data and display the information on frontend using <b>React charts</b>.
												</li>
												<li>
													Successfully <b>migrated</b> complete <b>infrastructure</b>, <b>code</b> and <b>data</b> of an organization from one <b>GCP</b> project to another. Created
											pipelines for the data to be <b>synchronized</b> across projects, so that data can be shared between them.
												</li>
												<li>
													Debugged and resolved multiple issues in multiple <b>GCP projects</b> for both Production and Development environments.
											Debugged cloud services including <b>Terraform</b> deployments, <b>Cloud Composer</b>, <b>Airflow</b>, <b>Cloud Dataflow</b>, <b>Cloud Functions</b> etc.
												</li>
												<li>
													Using <b>Terraform</b>, <b>Github Actions</b> and <b>GCP (Composer Airflow)</b>, created end-to-end Data Pipeline, reading, processing and
											storing almost <b>7 million</b> records each month. Terraform scripts get triggered by <b>GH Actions</b>, and create the Infrastructure
											i.e., <b>Composer Environment</b>, and then GH Actions update <b>Airflow DAGs</b>.
												</li>
												<li>
													Used <b>Terraform</b> to create <b>Datadog monitors</b> for a <b>DAG</b>, running in <b>Airflow</b>.
												</li>
												<li>
													Migrated a data pipeline that was previously running on <b>GCP's Dataflow in Scala</b> to a <b>Python-based pipeline</b>
													deployed on a <b>GCE instance</b>, saving approximately <b>6000 GBP per annum</b>. The migration required a deep
													understanding of both Scala and Python, as well as expertise in GCP's infrastructure. We optimized the pipeline's
													performance to handle the same workload as the previous pipeline, without sacrificing speed or accuracy,
													resulting in significant cost savings for our organization.
												</li>
											</ul>
										</p>
									</div>
									<span class="image"><img src="images/mlsense.jpg" alt="" /></span>
								</div>
								<hr>
								<div class="spotlight">
									<div class="content">
										<header class="major">
											<h2><b>Python Engineer</b> Intern at <b>ML Sense</b> <br></h2>
										</header>
										<p>
											<ul>
												<li>
													Developed a <b>Django React</b> app and created complete <b>CICD pipeline</b> using <b>GitHub Actions</b> to deploy on <b>Google App Engine</b>.
												</li>
												<li>
													Created multiple Python scrapers using <b>Selenium</b> and <b>BS4</b>, and completed a GUI based application, able to handle all the scrapers from a single User Interface.
												</li>
											</ul>
										</p>
									</div>
									<span class="image"><img src="images/mlsense.jpg" alt="" /></span>
								</div>
								<hr>
								<div class="spotlight">
									<div class="content">
										<header class="major">
											<h2>Freelancer at <b>Fiverr</b> <br></h2>
										</header>
										<p>
											<li>
												Worked on various client projects including <b>Scraping</b>, <b>Web development</b>, <b>Machine Learning</b> and <b>Database Designing</b>.
											</li>
										</p>
									</div>
									<span class="image"><img src="images/fiverr.png" alt="" /></span>
								</div>
							</section>

					</div>

				<!-- Footer -->
					<footer id="footer">
						<div style="justify-content: left;">
							<section>
								<img src="images/signature.png" />
							</section>
						</div>
						<div>
							<section>
								<h2><b>Contact</b></h2>
								<dl class="alt">
									<dt>Address</dt>
									<dd>Islampura &bull; Lahore &bull; Pakistan</dd>
									<dt>Phone</dt>
									<dd>(+92) 320 7341507</dd>
									<dt>Email</dt>
									<dd><a href="mailto:sairsyed2@gmail.com">sairsyed2@gmail.com</a></dd>
								</dl>
								<h2><b>Social</b></h2>
								<ul class="icons">
									<li><a href="https://www.linkedin.com/in/syedsair/" class="icon brands fa-linkedin alt"><span class="label">LinkedIn</span></a></li>
									<li><a href="https://github.com/syedsair" class="icon brands fa-github alt"><span class="label">GitHub</span></a></li>
									<li><a href="mailto:sairsyed2@gmail.com" class="icon fa-brands fa-envelope alt"><span class="label">Mail</span></a></li>
									<li><a href="https://www.facebook.com/sair.shah.908" class="icon brands fa-facebook-f alt"><span class="label">Facebook</span></a></li>
									<li><a href="https://www.instagram.com/s.sairas/" class="icon brands fa-instagram alt"><span class="label">Instagram</span></a></li>
								</ul>
							</section>
						</div>
						
						<p class="copyright">&copy; <a href="mailto:sairsyed2@gmail.com">Syed Sair Ali</a></p>
					</footer>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>